## 📑 Titanic 생존자 예측 모델 성능 비교 보고서  

### 1️⃣ 개요  
Titanic 데이터셋에서 결측치를 다양한 방법으로 처리한 후, 여러 모델을 학습하여 가장 높은 성능을 보이는 최적의 조합을 찾았다.  
본 보고서는 결측치 처리 방식별 데이터셋 조합과 해당 데이터셋을 학습한 모델의 성능을 비교하여 최적의 모델을 분석한다.  

---

### 2️⃣ 데이터 전처리 과정  

#### 📌 2.1 결측치 처리 방법  
각 변수(Age, Cabin, Embarked)의 결측치를 여러 방법으로 처리하여 조합된 데이터셋을 생성했다.  

변수      | 처리 방법                                       | 설명  
---------|---------------------------------|--------------------------------  
Age      | mean, median, knn, group_median, regression | 평균, 중앙값, KNN, 그룹 중앙값, 선형 회귀  
Cabin    | unknown, deck, has_cabin        | "Unknown" 대체, 첫 글자로 Deck 추출, 보유 여부 0/1 변환  
Embarked | mode, group_fare                | 최빈값 대체, Pclass+Fare 그룹 내 최빈값  

총 **30개(5×3×2)**의 데이터셋이 생성되었으며, 모든 조합을 AutoML을 활용하여 비교했다.  

---

### 3️⃣ AutoML을 활용한 모델 탐색  
H2O AutoML을 사용하여 다양한 모델을 학습한 후, 성능이 가장 우수한 모델을 선정하였다.  
각 데이터셋에서의 모델 성능을 비교한 결과, 다음의 데이터셋이 최적의 조합으로 선정되었다.  

최적 데이터셋 | RMSE   | MSE    
-------------|-------|-------  
A5_C2_E1    | 0.3527 | 0.1244  
A5_C2_E2    | 0.3527 | 0.1244  
A5_C3_E1    | 0.3548 | 0.1259  
A5_C3_E2    | 0.3548 | 0.1259  

➡ **결론: "Age: Regression", "Cabin: Deck or Has_Cabin", "Embarked: Mode or Group_Fare" 조합이 최적**  

---

### 4️⃣ 최적 모델 분석  
최적 데이터셋(A5_C2_E1, A5_C2_E2 등)에서 성능이 높은 모델은 **Stacked Ensemble**이었다.  

#### 📌 리더보드 상위 모델 분석  

Model                        | RMSE   | MSE    
---------------------------|-------|-------  
StackedEnsemble_BestOfFamily | 0.3527 | 0.1244  
StackedEnsemble_AllModels   | 0.3558 | 0.1265  
GBM_2                       | 0.3571 | 0.1275  
GBM_3                       | 0.3606 | 0.1301  

✔ **StackedEnsemble_BestOfFamily** 모델이 가장 높은 성능을 보였다.  
✔ **Gradient Boosting (GBM) 기반 모델도 높은 성능을 기록**했다.  
✔ XGBoost 및 GLM 모델은 상대적으로 성능이 낮았다.  

---

### 5️⃣ 결론 및 향후 개선 방향  

✅ **결론:**  
1. **결측치 처리 방식이 성능에 영향을 미쳤다.**  
   - `Regression` 방식의 Age 대체가 가장 효과적이었음.  
   - `Deck` 또는 `Has_Cabin` 방식이 Cabin 정보 활용에 유리했음.  
   - `Mode` 또는 `Group_Fare` 방식이 Embarked 처리에서 우수했음.  

2. **AutoML을 활용하여 최적 모델을 탐색한 결과, Stacked Ensemble이 가장 우수한 성능을 보였다.**  
   - GBM 계열 모델이 높은 성능을 보였으며, XGBoost는 상대적으로 성능이 낮았다.  

✅ **향후 개선 방향:**  
📌 Feature Engineering을 추가하여 성능을 더 개선할 가능성이 있음.  
📌 모델 파라미터 튜닝을 통해 GBM/XGBoost 계열 모델을 최적화할 필요 있음.  
📌 데이터 증강 기법을 활용하여 모델 성능을 더 향상할 수 있을 것.  
