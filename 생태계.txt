AI 학습 생태계

1. 데이터 (Data):
   - AI 모델 학습에 필수적인 요소로, 모델이 학습할 정보를 제공합니다.
   - 예시: 이미지, 텍스트, 음성, 센서 데이터 등.

2. 데이터 전처리 (Data Preprocessing):
   - 원시 데이터를 모델이 이해할 수 있는 형태로 변환하는 과정.
   - 예시: 결측값 처리, 데이터 정규화, 데이터 증강 등.

3. 모델 (Model):
   - 데이터를 학습하여 패턴을 찾고 예측할 수 있는 수학적 구조.
   - 예시: 인공 신경망, 결정 트리, 서포트 벡터 머신 등.

4. 학습 알고리즘 (Learning Algorithm):
   - 데이터를 통해 모델을 학습시키는 방법론으로, 손실 함수를 최소화하는 방향으로 학습합니다.
   - 예시: 경사 하강법(Gradient Descent), 확률적 경사 하강법(SGD), Adam 등.

5. 손실 함수 (Loss Function):
   - 모델의 예측 값과 실제 값 사이의 차이를 측정하여 학습의 방향성을 제공합니다.
   - 예시: 평균 제곱 오차(MSE), 크로스 엔트로피 등.

6. 최적화 (Optimization):
   - 손실 함수를 최소화하기 위해 모델의 가중치를 업데이트하는 과정.
   - 예시: Adam, RMSprop 등.

7. 활성화 함수 (Activation Function):
   - 뉴런의 출력값을 결정하여 모델의 비선형성을 제공합니다.
   - 예시: ReLU, 시그모이드(Sigmoid), 하이퍼볼릭 탄젠트(Tanh) 등.

8. 학습률 (Learning Rate):
   - 모델의 가중치를 업데이트할 때 이동하는 양을 결정하는 하이퍼파라미터.

9. 평가 지표 (Evaluation Metric):
   - 모델의 성능을 측정하기 위한 지표.
   - 예시: 정확도(Accuracy), 정밀도(Precision), 재현율(Recall), F1-Score 등.

10. 검증 (Validation):
   - 모델의 성능을 학습 중에 평가하여 과적합을 방지하는 과정.

11. 테스트 (Test):
   - 학습과 검증 이후, 모델의 일반화 성능을 최종적으로 평가하는 단계.

12. 하이퍼파라미터 튜닝 (Hyperparameter Tuning):
   - 모델 성능을 최적화하기 위해 학습률, 배치 크기 등 하이퍼파라미터를 조정하는 과정.

13. 앙상블 학습 (Ensemble Learning):
   - 여러 모델을 결합하여 성능을 향상시키는 방법.
   - 예시: 배깅(Bagging), 부스팅(Boosting), 스태킹(Stacking).

14. 데이터 분할 (Train, Validation, Test Split):
   - 모델 학습에 사용하는 데이터를 훈련, 검증, 테스트로 나누어 사용합니다.

15. 과적합 (Overfitting) & 과소적합 (Underfitting):
   - 과적합: 모델이 학습 데이터에 지나치게 맞춰져 일반화 능력이 떨어지는 현상.
   - 과소적합: 모델이 충분히 학습하지 못해 성능이 낮은 현상.
